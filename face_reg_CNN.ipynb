{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archigarg1234/face-recognition-cnn/blob/main/face_reg_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "42406ae0",
      "metadata": {
        "id": "42406ae0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2  # opencv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "34510274",
      "metadata": {
        "id": "34510274"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "814573cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "814573cb",
        "outputId": "7445aae4-4972-4ea3-ebfe-a54c5722c25e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c88706975d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.manual_seed(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b3a8e786",
      "metadata": {
        "id": "b3a8e786"
      },
      "outputs": [],
      "source": [
        "#GET CURRENT DIRECTORY\n",
        "# dir = Path.cwd()\n",
        "data = pd.read_csv('fer2013.csv')\n",
        "# data.head(10)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "196d035e",
      "metadata": {
        "id": "196d035e"
      },
      "outputs": [],
      "source": [
        "del data[\"Usage\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "aa7dabfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa7dabfc",
        "outputId": "18480530-bb4f-4b61-ab9c-c1791384d393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'anger',\n",
              " 1: 'disgust',\n",
              " 2: 'fear',\n",
              " 3: 'happiness',\n",
              " 4: 'sadness',\n",
              " 5: 'surprise',\n",
              " 6: 'neutral'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n",
        "label_to_text\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "59ff16b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "59ff16b7",
        "outputId": "8f844dea-fa40-491d-c216-164e1668af69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "3    8989\n",
              "6    6198\n",
              "4    6077\n",
              "2    5121\n",
              "0    4953\n",
              "5    4002\n",
              "1     547\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data['emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "813525b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "813525b4",
        "outputId": "949bf287-3487-4598-ab0b-da1e9a51319c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting the above distribution\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "ax = sns.countplot(x=\"emotion\", data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0db79ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0db79ba5",
        "outputId": "1a2375aa-64e7-4141-c9ea-e123c62402a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62923, 1)   (62923,)\n"
          ]
        }
      ],
      "source": [
        "#Data preprocessing\n",
        "#1 Class imbalance\n",
        "\n",
        "x_data = data['pixels']\n",
        "y_data = data['emotion']\n",
        "\n",
        "# Perform Random Over Sampling to balance the data\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto')\n",
        "\n",
        "x_data, y_data = oversampler.fit_resample(x_data.values.reshape(-1,1), y_data)\n",
        "print(x_data.shape,\" \",y_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8a9a54f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "8a9a54f4",
        "outputId": "e8492616-1bbb-4b55-d37e-3e625fbd72fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
              "                               ...                        \n",
              "62918    23 34 32 58 78 77 88 108 156 154 149 146 125 1...\n",
              "62919    224 224 224 225 225 232 104 67 30 19 80 98 92 ...\n",
              "62920    138 89 110 104 96 122 125 125 125 136 147 148 ...\n",
              "62921    88 83 70 59 61 53 40 37 43 46 34 46 62 67 76 1...\n",
              "62922    37 27 24 30 28 26 32 37 43 51 50 60 68 81 122 ...\n",
              "Length: 62923, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62918</th>\n",
              "      <td>23 34 32 58 78 77 88 108 156 154 149 146 125 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62919</th>\n",
              "      <td>224 224 224 225 225 232 104 67 30 19 80 98 92 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62920</th>\n",
              "      <td>138 89 110 104 96 122 125 125 125 136 147 148 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62921</th>\n",
              "      <td>88 83 70 59 61 53 40 37 43 46 34 46 62 67 76 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62922</th>\n",
              "      <td>37 27 24 30 28 26 32 37 43 51 50 60 68 81 122 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62923 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "x_data = pd.Series(x_data.flatten())\n",
        "x_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "14a91f18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14a91f18",
        "outputId": "c10e4f06-3b5e-44d2-bfa4-e9117dc4258f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.27450982, 0.3137255 , 0.32156864, ..., 0.41568628, 0.42745098,\n",
              "        0.32156864],\n",
              "       [0.5921569 , 0.5882353 , 0.5764706 , ..., 0.75686276, 0.7176471 ,\n",
              "        0.72156864],\n",
              "       [0.90588236, 0.83137256, 0.6117647 , ..., 0.34509805, 0.43137255,\n",
              "        0.59607846],\n",
              "       ...,\n",
              "       [0.3019608 , 0.30588236, 0.30980393, ..., 0.49019608, 0.2627451 ,\n",
              "        0.26666668],\n",
              "       [0.33333334, 0.32941177, 0.3529412 , ..., 0.22745098, 0.28627452,\n",
              "        0.32941177],\n",
              "       [1.        , 0.99607843, 1.        , ..., 0.99607843, 1.        ,\n",
              "        1.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "x_data = np.array(list(map(str.split, x_data)), np.float32)\n",
        "x_data/=255\n",
        "\n",
        "x_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9b8a2d83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b8a2d83",
        "outputId": "eeabf22e-6f5a-4f93-eea6-ac1e0de37b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62923, 48, 48, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x_data = x_data.reshape(-1, 48, 48, 1)\n",
        "x_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2b0bd096",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b0bd096",
        "outputId": "9bc127da-812c-4e91-f386-f80901a5835b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62923, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y_data = np.array(y_data)\n",
        "y_data = y_data.reshape(y_data.shape[0], 1)\n",
        "y_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c1ecb02f",
      "metadata": {
        "id": "c1ecb02f"
      },
      "outputs": [],
      "source": [
        "# Split the data and create train-test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.1, random_state = 45)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "824becee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824becee",
        "outputId": "a82ad13e-6e35-4a65-aba3-c348ce3f9fe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((56630, 48, 48, 1), (6293, 48, 48, 1), (56630, 1), (6293, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9d3029b4",
      "metadata": {
        "id": "9d3029b4"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor(x_train)\n",
        "y_train = torch.tensor(y_train)\n",
        "x_test = torch.tensor(x_test)\n",
        "y_test = torch.tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a39752a",
      "metadata": {
        "id": "4a39752a",
        "outputId": "3e4498ff-3c71-4759-f5bc-b14ef38b22c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([56630, 7])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y_train = torch.nn.functional.one_hot(y_train, 7)\n",
        "# y_train = y_train.squeeze(1)\n",
        "# y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d7f970",
      "metadata": {
        "id": "48d7f970",
        "outputId": "83edf680-3fc7-4b0a-c52d-49bfce2bc4b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6293, 7])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y_test = torch.nn.functional.one_hot(y_test, 7)\n",
        "# y_test = y_test.squeeze(1)\n",
        "# y_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c92c53",
      "metadata": {
        "id": "e6c92c53"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ace758ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ace758ca",
        "outputId": "d37fd852-6ba8-413d-e7c9-a0fa658de91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2007841572.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_train_tensor = torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
            "/tmp/ipython-input-2007841572.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_tensor  = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
            "/tmp/ipython-input-2007841572.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train, dtype=torch.long).squeeze()  # shape: [56630]\n",
            "/tmp/ipython-input-2007841572.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor  = torch.tensor(y_test, dtype=torch.long).squeeze()   # shape: [6293]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert to float32 and permute channels\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "x_test_tensor  = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "\n",
        "# Convert labels to long\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).squeeze()  # shape: [56630]\n",
        "y_test_tensor  = torch.tensor(y_test, dtype=torch.long).squeeze()   # shape: [6293]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "09680387",
      "metadata": {
        "id": "09680387"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "test_dataset  = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603cccb7",
      "metadata": {
        "id": "603cccb7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ab85648b",
      "metadata": {
        "id": "ab85648b"
      },
      "source": [
        "# Model Architecture\n",
        " We are using CNN because they work best on grid type dataset and also identifies features like edges, textures, curves of the images. Architecture involves feature extraction (convolutional layer(identifies minute featuers), pooling(reduces the size of your tensors) then flatten it, and then we do classification layer.)\n",
        "\n",
        " First few layers: learns features like edges, striaght line, slant lines, etc.\n",
        "\n",
        " Middle layers of CNN: Learns shapes like circles, squars etc.\n",
        "\n",
        " Last layers of CNN - Detects objects in the images like if it is a CAT or a Dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b6f26826",
      "metadata": {
        "id": "b6f26826"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "74d94a93",
      "metadata": {
        "id": "74d94a93"
      },
      "outputs": [],
      "source": [
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, num_classes = 7):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "\n",
        "        #1st layer\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=2,stride=1, padding = 0),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Flatten + Fully Connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 250),  # adjust based on final spatial size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(250, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "35083089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35083089",
        "outputId": "032f664f-6ace-4b46-b081-6bc7f42aef42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.6534\n",
            "Epoch [2/10], Loss: 1.3070\n",
            "Epoch [3/10], Loss: 1.1091\n",
            "Epoch [4/10], Loss: 0.9725\n",
            "Epoch [5/10], Loss: 0.8799\n",
            "Epoch [6/10], Loss: 0.7966\n",
            "Epoch [7/10], Loss: 0.7247\n",
            "Epoch [8/10], Loss: 0.6576\n",
            "Epoch [9/10], Loss: 0.5991\n",
            "Epoch [10/10], Loss: 0.5505\n"
          ]
        }
      ],
      "source": [
        "#initailize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmotionCNN(num_classes=7).to(device)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        #forward pass\n",
        "        outputs = model(images)\n",
        "        #loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        #Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        #update grads\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr2QO5uJTD62",
        "outputId": "75b98928-51a1-4e75-fca6-c7bfe0b9485c"
      },
      "id": "jr2QO5uJTD62",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionCNN(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.25, inplace=False)\n",
              "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (17): ReLU()\n",
              "    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=250, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=250, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "# Turn off gradient tracking\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        # Move data to GPU if available\n",
        "        images, labels = images.to(device),  labels.to(device)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Compute loss if you want\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Update correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # Final metrics\n",
        "\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxW4mFDVEyB",
        "outputId": "8aa80552-d45a-4b3a-cb76-05b1c8f17337"
      },
      "id": "JVxW4mFDVEyB",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8352, Test Accuracy: 71.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "# Turn off gradient tracking (faster + less memory)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Move data to GPU if available\n",
        "        images = images.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Compute loss if you want\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Update correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Final metrics\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "\n",
        "print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bffqYAkBVP22",
        "outputId": "1b52a134-bda4-461a-c44d-65eb2d5fd78c"
      },
      "id": "bffqYAkBVP22",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5599, Train Accuracy: 81.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Getting Classification Report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvWfNozhXMYb",
        "outputId": "035896a7-bd3c-4d2e-ebbd-cbd899782205"
      },
      "id": "TvWfNozhXMYb",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78      8054\n",
            "           1       1.00      0.88      0.94      8094\n",
            "           2       0.79      0.74      0.76      8109\n",
            "           3       0.82      0.90      0.86      8083\n",
            "           4       0.73      0.68      0.70      8101\n",
            "           5       0.94      0.90      0.92      8120\n",
            "           6       0.71      0.80      0.75      8069\n",
            "\n",
            "    accuracy                           0.81     56630\n",
            "   macro avg       0.82      0.81      0.81     56630\n",
            "weighted avg       0.82      0.81      0.81     56630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"Facial_recognition_saved_model.pth\")"
      ],
      "metadata": {
        "id": "hl_6YfrycZk_"
      },
      "id": "hl_6YfrycZk_",
      "execution_count": 66,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}